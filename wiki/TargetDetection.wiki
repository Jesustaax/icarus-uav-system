[TargetDetection#Operation Operating Instructions]

[PrimaryController Primary Controller]
[FlightController Flight Controller]
[MotionController Motion Controller]

= Tasks =

= Milestones =

= Summary =

[http://iarc.angel-strike.com/IARC_6th_Mission_Rules.pdf IARC Mission 6 Rules]

The objective of the AUVSI IARC 6th Mission is to have a UAV fly into an office-space (which includes hallways, rooms, rooms off rooms, etc), locate a flash-drive in an unknown location, retrieve the flash drive and leave the office-space.  The office-space is in an environment designed to simulate a foreign government with no access to GPS signals.

Two key parts of the competition are to a) navigate the office-space using the available signage placed in the environment and b) visually identify the flash drive in the office-space.  Both of these components are complex, as the signage is in a foreign language and the flash drive may be placed anywhere in the office-space.

[http://iarc.angel-strike.com/security_compound_signs.pdf Signage examples]

[http://iarc.angel-strike.com/Images/FlashDriveDimensions.jpg Flash Drive]

This project is intended for the UIC class ECE 559: Neural Networks

== Basic Operation ==

For navigating around the officespace, there are 3 different offices with associated signage placed in the environment.  These are arabic signs, which translate to "Chief of Security", "Ministry of Torture" and "Security Compound".  The Flash Drive is known to be in the "Chief of Security" office.

To get the current UAV's position, it uses the project shown before in [ICARUS_SLAM].  To determine the UAV's waypoints, it uses 2 Neural Networks:  The first one is used to define which sign, if any, is in the current FOV of the UAV.  If the sign in view is the "Chief of Security" sign, the 2nd Neural Network is employed, which identifies the center point of that sign.  The UAV then determines the distance between itself and the center of that sign, and calculates a new waypoint based on its current position, feeds it to the Flight Controller when in turns generates the correct motor outputs to navigate successfully to that sign.  

== In Depth Operation ==
 * The UAV preprocesses the images that come from the Kinect.  It converts the RGB image to a grayscale image, and performs some contrast stretching since all the room signs are black text on a white background.
 * A Classification Neural Network (BP) is used to classify each processed image.  The identifiable classes are [ChiefSecurity,MinistryTorture,SecurityCompound,None].
 * If the recognized image class identified is the ChiefSecurity
= Media =

= Installation/Development Instructions =

= Operation =

== Compiling ==

= Resources =

[http://pybrain.org/docs/index.html#tutorials PyBrain]

[http://docs.opencv.org/modules/ml/doc/ml.html OpenCV Machine Learning]

[http://www.pirobot.org/blog/0002/ PIRobot Neural Network & ROS]