#summary One-sentence summary of this page.

[ICARUS_OBSTACLE_AVOIDANCE#Operation Operating Instructions]
[https://bitbucket.org/uicrobotics/icarus_oa ROS Source Code]
[https://www.dropbox.com/sh/5k0mwuku06bbsmt/agLkb_57Lh Propeller Source Code]

[PrimaryController Primary Controller]
[FlightController Flight Controller]
[MotionController Motion Controller]


= Tasks =
 * CAD Conceptual Design (DONE)
 * Dev Primary and Motion Controllers to work with current Mode FSM. (DONE)
 * Fuse AI-OA_Sonic and AI-OA_Kinect to provide better Obstacle Avoidance maneuvers.

== OA_Kinect ==
 * Dev Code to acquire (and save on mouseclick) Disparity Images (DONE)
 * Develop appropriate Image Filter
 * Develop AI algorithm (AI-OA_Kinect) relating Kinect tracked obstacles and input/output motor commands. 

== OA_Sonic ==
 * Dev Code for MC to measure distances, receive motor commands and output motor commands. (DONE)
 * Develop AI algorithm (AI-OA_Sonic) relating Ultrasonic distances and input/output motor commands.

= Milestones =

== OA_Kinect ==
  * Acquire images with Kinect into a Laptop running Ubuntu/ROS
  * Compare/contrast different imaging capabilities on the Kinect to find the most appropriate ones for this project, i.e. its RGB camera, IR/Depth Camera, Disparity, etc.
  * Determine "mask" of quadrotor that would be in the Kinect's FOV and adjust the acquired image accordingly, i.e. find how it changes when the Propeller's are spinning.
  * Implement obstacle tracking algorithm and show tracked obstacles in a GUI window.
  * Transmit obstacle locations/trajectories to the microcontroller.

== OA_Sonic ==
= Introduction =

== Summary ==
This project builds upon the previous project, [ICARUS_SLAM].  This project also uses the Quickstart and QuickstartPlus, along with Ultrasonic sensors, Microsoft Kinect and an AI algorithm to provide obstacle avoidance.  This can be used in cluttered environments, such as office spaces.

This project is intended for the UIC class CS 411: Artificial Intelligence and ECE 415: Image Analysis and Computer Vision 1

== Basic Operation ==

This project employs obstacle avoidance using the Microsoft Kinect and Ultrasonic Sensors placed around the UAV, due to advantages and disadvantages of each sensor.

The Ultrasonic Sensors have very little resolution, as they only report back the distance to the nearest obstacle they see.  But, since they have a fairly wide field of view and they consume little system resources (memory, space, weight, energy, etc) and they respond quickly to changes in their environment they are used to provide immediate feedback to the AI algorithm used to adjust the motor speeds to avoid obstacles they perceive.

The Kinect Sensor has a Visible and an IR Laser Array/Camera onboard.  For the purposes of this project only the IR Laser Array/Camera is used.  The Kinect provides a much more detailed view of what the UAV sees in front of itself.  Since it is assumed that the UAV will primarily be flying forward, the optimal placement of the Kinect of the view where the UAV will be flying is towards the front of the UAV.  The Kinect is able to much more accurately tell where obstacles are in its FOV, to provide guidance to the Mission Controller not only that there are obstacles but what direction would be the best to avoid them. 

[http://dgitz.ipower.com/ICARUSRepo/Media/Projects/ICARUS_OA/SystemDiagram_Simple.png]
Simplified Diagram

== AI-OA_Kinect == 
=== Image Analysis ===
As the Kinect has several different imaging capabilities, it is necessary to select the one that will have the best results for the AI algorithm.  Below is a sequence of pictures, in a cluttered environment, of an obstacle placed in the foreground of the Kinect.  The picture on the left is an image taken directly from the RGB camera, while the picture on the right is one taken from the IR/Depth Camera.

[http://dgitz.ipower.com/ICARUSRepo/Media/Projects/ICARUS_OA/AlgorithmImages/image1.jpg]
No obstacles here, just the environment.

[http://dgitz.ipower.com/ICARUSRepo/Media/Projects/ICARUS_OA/AlgorithmImages/image2.jpg]
A small wooded rod.

[http://dgitz.ipower.com/ICARUSRepo/Media/Projects/ICARUS_OA/AlgorithmImages/image3.jpg]
A larger wooden board.

[http://dgitz.ipower.com/ICARUSRepo/Media/Projects/ICARUS_OA/AlgorithmImages/image4.jpg]
The same wooden board again.

Obviously, the IR/Depth Camera is much more able to detect the difference between an obstacle in the foreground and an obstacle in the background in the Kinect's FOV.  Also, the IR camera will work just as well in a dark environment.

= Media =

[http://dgitz.ipower.com/ICARUSRepo/Media/Projects/ICARUS_OA/Flyer_Assy.png]
ICARUS Flyer

[http://dgitz.ipower.com/ICARUSRepo/Media/Projects/ICARUS_OA/Flyer_AssywUltrasonicBeams.png]
ICARUS Flyer w/ Ultrasonic Beams

[http://dgitz.ipower.com/ICARUSRepo/Media/Projects/ICARUS_OA/Flyer_AssywKinectFOV.png]
ICARUS Flyer w/ Kinect Field of View for Visible and IR Camera

[http://dgitz.ipower.com/ICARUSRepo/Media/Projects/ICARUS_OA/Flyer_AssywEverything.png]
ICARUS Flyer w/ Kinect Field of View and Ultrasonic Beams

[https://www.dropbox.com/s/3723pg8ld2cp65k/ProgramFlowchart.pptx Software Flowchart]

[https://www.dropbox.com/s/qtkywga5dyuwr1r/Software%20Documentation.docx Software Documentation]

= Installation/Development Instructions =

== Compiling ==
{{{

}}}


== Commit ==
 # Add any uncommitted files:
{{{
git add .
}}}
 # Make a comment on the commit and then push it to the main branch.
{{{
git commit -m "Comment Text"
git push -u origin master
}}}

= Operation =
== Headless ==
 * In Terminal 1:
{{{
roscore
}}}

 * In Terminal 2:
{{{
roslaunch oa slow_computer2.launch
}}}
 
 * In Terminal 3:
{{{
sudo chmod 0777 /dev/ttyACM0
rosservice call /oa/ros_ui_b pause false
}}}

Execute the main program with the following:
{{{
python nodes/primarycontroller.py
}}}
The following options are available.  Use the text in the <> where applicable, | signifies different options, and omit the <> and |:
 * Connection to GCS (Transmit GPS and Attitude Completed)
{{{
--gcs-device-type=<udp|Serial>
--gcs-device=<Device> #Where Device is an IP address if the type is udp, or a Serial Device such as /dev/ttyUSB0 or /dev/ttyACM0
--gcs-device-speed=<Speed> #Where Speed is a compatible baud rate if the type is Serial (default is 115200) and not used the type is udp 
}}}
 * Connection to Flight Controller (Receive Attitude Completed)
{{{
--fc-device-type=<udp|Serial>
--fc-device=<Device> #Where Device is an IP address if the type is udp, or a Serial Device such as /dev/ttyUSB0 or /dev/ttyACM0
--fc-device-speed=<Speed> #Where Speed is a compatible baud rate if the type is Serial (default is 115200) and not used the type is udp 
}}}
 * Connection to Flight Controller GPS (In Progress)
{{{
--fcgps-device-type=<udp|Serial>
--fcgps-device=<Device> #Where Device is an IP address if the type is udp, or a Serial Device such as /dev/ttyUSB0 or /dev/ttyACM0
--fcgps-device-speed=<Speed> #Where Speed is a compatible baud rate if the type is Serial (default is 115200) and not used the type is udp 
}}}
 * Connection to Motion Controller (In Progress)
{{{
--mc-device-type=<udp|Serial>
--mc-device=<Device> #Where Device is an IP address if the type is udp, or a Serial Device such as /dev/ttyUSB0 or /dev/ttyACM0
--mc-device-speed=<Speed> #Where Speed is a compatible baud rate if the type is Serial (default is 115200) and not used the type is udp 
}}}
 * Connection to Remote (Transmit GPS and Attitude In Progress)
{{{
--remote-device-type=<udp|Serial>
--remote-device=<Device> #Where Device is an IP address if the type is udp, or a Serial Device such as /dev/ttyUSB0 or /dev/ttyACM0
--remote-device-speed=<Speed> #Where Speed is a compatible baud rate if the type is Serial (default is 115200) and not used the type is udp 
}}}

 * Example
{{{
oa/nodes/primarycontroller.py --fcgps-device-type=Serial --fcgps-device=/dev/ttyUSB0 --fc-device-type=Serial --fc-device=/dev/ttyACM0 --gcs-device-type=udp --gcs-device=10.7.45.208
}}}

== GUI ==
 * In Terminal 1:
{{{
roscore
}}}

 * In Terminal 2:
{{{
rosrun rviz rviz
}}}

 * In Terminal 3:
{{{
roslaunch oa slow_computer2.launch
}}}
When GUI opens, press SPACE.
In RVIZ, Global Status should turn from ERROR to OK after moving.
 * In Terminal 4:
{{{
rosrun tf tf_echo /map /camera_link
}}}

= References =
[http://wiki.python.org/moin/PythonForArtificialIntelligence]