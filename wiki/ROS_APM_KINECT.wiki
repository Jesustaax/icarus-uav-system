#summary ROS, APM and Kinect

= Introduction =

The objective of this project is to implement a system that has a computer running ROS with a Kinect doing target tracking, and outputting commands via MAVLink to an APM Board.

This project is for the UIC ECE 452 Course: Robotics.  This is an ongoing project for the Spring 2013 Semester and as such is still a work in progress.  All code/information/documentation will be made available upon completion.

= Pictures =
[http://dgitz.ipower.com/ICARUSRepo/Media/Projects/ROS_APM/ROS_APM_Kinect_1.jpg]

[http://dgitz.ipower.com/ICARUSRepo/Media/Projects/ROS_APM/ROS_APM_Kinect_2.png]

= Videos =
[http://www.youtube.com/watch?v=X8OeJrsW6gA&feature=youtu.be Project Overview Video]
= Details =

== System Overview ==
  * [http://dgitz.ipower.com/ICARUSRepo/Media/Flyer/Design/LogicalDesign/SystemDiagram.png System Diagram]
  * Work Not Completed
    * Implement on ArduCopter
    * Auto-start Script
    * Clean up Code
    * Input HSV Values for Color Tracking   
  * Work Completed
    * All Electronics Assembled
    * ROS Installation/Configuration
    * ROS To/From APM Communication
    * ROS Set RC Channels Directly (Optional)
    * ROS Set Pitch/Roll Setpoints
    * Kinect Color blob tracking
    * Code Integration:  Kinect and APM_ROS Code in same project.
    * Target Pitch Setpoints
    * Target Yaw Setpoints
    * Measure Distance to Target
    * Wiki Documentation
    * Finish mounting hardware/cables
    * Upload to CVRL BitBucket:  [https://bitbucket.org/uicrobotics/ros_apm_kinect/wiki/Home Link]
  * Future Work
    * Image Tracking adjusts Roll Angle
    * Integrate ROS w/ GCS System
    * Track other kinds of Targets (geometry, etc)
    * Implement on an Embedded Controller

== Components ==
=== Laptop ===
[http://www.ubuntu.com/download/desktop https://wiki.ubuntu.com/IconsPage?action=AttachFile&do=get&target=iconCircle48.png] 
[http://www.warp1337.com/sites/www.warp1337.com/files/fuerte-320w.jpg]
  A laptop running Ubuntu 12.04 was installed with the Robot Operating System (ROS)-Fuerte.  A laptop was used as it would simplify development, and the usage of ROS implies that it is somewhat device independent.   Here's a list of dependent packages:
    * [https://github.com/mavlink/mavlink MAVLink]
    * [http://www.ros.org/wiki/openni_kinect Openni Kinect Driver]

=== DIYDrones APM ===

[http://store.diydrones.com/v/vspfiles/photos/BR-ArduPilotMega-03-2T.jpg]
  The [http://store.diydrones.com/APM_2_0_Kit_p/br-ardupilotmega-03.htm DIYDrones APM] is already used as a Flight Controller in the ICARUS QTW Flyer.  While it has many functions, including an AHRS System, it lacks the ability to connect to more advanced sensors (such as the Kinect) and the programming space left (after using the Arduplane/Arducopter code) is quite small.  This project slightly modified the ArduPlane 2.68 Default Code.  The download listed above contains the complete APM code required for this project.  If you'd like to make the necessary changes to your own code here they are:

==== Arduplane.ino ====
After the {{{// Roll, pitch, yaw and thrust commands}}} lines:
{{{
 #if ATTITUDE_COMMAND == ENABLED
 static bool in_command = false;
 static uint32_t command_fs_timer;
 static long roll_command;
 static long pitch_command;
 static long yaw_command;
 static int thrust_command;
 #endif
}}}

In the update_current_flight_mode(void) function, in the default case after calc_throttle();
{{{
#if ATTITUDE_COMMAND == ENABLED

            check_command();
            if (in_command) 
            {
                    nav_pitch_cd = pitch_command;
                    nav_roll_cd = roll_command;
                    g.channel_throttle.servo_out = thrust_command;
                    g.channel_rudder.servo_out = yaw_command;
            }
            else
            {
              
            }
#endif
}}}

Before the check_command() function:
{{{
#if ATTITUDE_COMMAND == ENABLED
 static void check_command() {
      if (millis() - command_fs_timer > FAILSAFE_SHORT_TIME) {
        in_command = false;       
      }
 }
 #endif
}}}

==== Attutide.ino ===
Unfortunately the ArduPlane 2.68 Code does not perform Yaw PID Control as it does with Pitch and Roll.  So instead of setting the desired Yaw state, we have to set the desired Yaw Servo Angle directly.  This requires the following modification in the calc_nav_yaw function:

{{{
#if APM_CONTROL == DISABLED
#if ATTITUDE_COMMAND == DISABLED
    // always do rudder mixing from roll
    g.channel_rudder.servo_out = g.kff_rudder_mix * g.channel_roll.servo_out;
#endif
    // a PID to coordinate the turn (drive y axis accel to zero)
    Vector3f temp = ins.get_accel();
    int32_t error = -temp.y*100.0;
#if ATTITUDE_COMMAND == DISABLED
    g.channel_rudder.servo_out += g.pidServoRudder.get_pid(error, speed_scaler);
#endif
#else // APM_CONTROL == ENABLED
    // use the new APM_Control library
	g.channel_rudder.servo_out = g.yawController.get_servo_out(speed_scaler, ch4_inf < 0.25) + g.channel_roll.servo_out * g.kff_rudder_mix;
#endif
}
}}}

==== config.h ===
Add:
{{{
#ifndef ATTITUDE_COMMAND
#define ATTITUDE_COMMAND ENABLED
#endif
}}}

==== GCS_Mavlink.ino ====
In the GCS_MAVLINK::handleMessage function:
{{{
 #if ATTITUDE_COMMAND == ENABLED              
     case  MAVLINK_MSG_ID_SET_ROLL_PITCH_YAW_THRUST:
         { 
           // Allows a ground control station to command attitude/thrust set points
             //if(msg->sysid != g.sysid_my_gcs) break;            // Only accept control from our gcs
             mavlink_set_roll_pitch_yaw_thrust_t packet;
             mavlink_msg_set_roll_pitch_yaw_thrust_decode(msg, &packet);
             if (mavlink_check_target(packet.target_system,packet.target_component)) break;
                 
             roll_command = (long)(mavlink_msg_set_roll_pitch_yaw_thrust_get_roll(msg)*100.0*180.0/3.14159);
             pitch_command = (long)(mavlink_msg_set_roll_pitch_yaw_thrust_get_pitch(msg)*100.0*180.0/3.14159);
             yaw_command = (long)(mavlink_msg_set_roll_pitch_yaw_thrust_get_yaw(msg)*100.0*180.0/3.14159);
             thrust_command = (int)(mavlink_msg_set_roll_pitch_yaw_thrust_get_thrust(msg)*100.0);            
             
             in_command = true;
             command_fs_timer = millis();
             break;
         }
 #endif
}}}
=== Kinect Sensor ===
[http://img.gawkerassets.com/img/17nnc7oa1rdrijpg/xlarge.jpg]

  This [http://www.amazon.com/Kinect-Sensor-Adventures-Xbox-360/dp/B002BSA298/ref=sr_1_1?ie=UTF8&qid=1360093357&sr=8-1&keywords=kinect+xbox Kinect Sensor] was purchased through UIC to be used on this project. 

= Operating Instructions =
# Start the ROS Core
In Terminal 1:
{{{
roscore
}}}
# Start the Kinect Camera Driver
In Terminal 2:
{{{
roslaunch openni_launch openni.launch
}}}
# Start a Kinect RGB Video feed (used in the Node Script)
In Terminal 3:
{{{
rosrun image_view image_view image:=/camera/rgb/image_color
}}}
# Start a Kinect Depth Video feed (used in the Node Script)
In Terminal 4:
{{{
rosrun image_view image_view image:=/camera/depth/image
}}}
# Start the ROS Node Script
In Terminal 5:
{{{
rosmake ros_apm_kinect
roscd ros_apm_kinect
sudo chmod 0777 /dev/ttyACM0
nodes/ros_apm_kinect.py --device=/dev/ttyACM0 --rate=115200
}}}
== References ==

I'd like to thank the following people/organizations for their contributions to this project:
  * The UIC CVRL Robotics Laboratory.
  * Loughborough University Centre for Autonomous Systems for their [https://code.google.com/p/lucas-research/wiki/APMSimulink source code] dealing with interfacing the APM with MAVLink.
  * Yogesh Girdhar for his contributions with interfacing the [https://www.google.com/search?q=roscopter&aq=f&oq=roscopter&aqs=chrome.0.59l2j60j62l3.997&sourceid=chrome&ie=UTF-8 APM with ROS].